# Spark Application Configuration
spark.master=yarn
spark.submit.deployMode=client

# Executor Configuration
spark.executor.memory=8g
spark.executor.cores=8
spark.executor.instances=8

# Driver Configuration
spark.driver.memory=4g
spark.driver.cores=2

# Adaptive Query Execution
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer

# HDFS Configuration
spark.hadoop.fs.defaultFS=hdfs://localhost:9000

# Logging
spark.eventLog.enabled=true
spark.eventLog.dir=hdfs://localhost:9000/spark-logs

# Add these logging configurations
spark.driver.extraJavaOptions=-Dlog4j.rootCategory=WARN,console -Dlog4j.logger.org.apache.hadoop.yarn=ERROR -Dlog4j.logger.org.apache.parquet=ERROR
spark.executor.extraJavaOptions=-Dlog4j.rootCategory=WARN,console -Dlog4j.logger.org.apache.hadoop.yarn=ERROR -Dlog4j.logger.org.apache.parquet=ERROR


# Memory Management
spark.sql.adaptive.shuffle.targetPostShuffleInputSize=64MB
spark.sql.adaptive.advisoryPartitionSizeInBytes=128MB

spark.jars=mysql-connector-j-9.3.0.jar
